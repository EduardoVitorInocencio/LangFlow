import sys
import os

# Adiciona o caminho absoluto do backend ao sys.path
sys.path.append(os.path.abspath("C:/Users/edinocencio/langflow/backend"))
from dotenv import find_dotenv, load_dotenv

load_dotenv(find_dotenv())

from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai.chat_models import ChatOpenAI
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.agent import AgentFinish
from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser
from langchain.agents import AgentExecutor
from langchain.memory import ConversationBufferMemory
from langchain_core.utils.function_calling import convert_to_openai_function
from langchain.agents.format_scratchpad import format_to_openai_function_messages
from tools.tools import busca_wikipedia, actual_temperature_seach, find_cep, currency_search

memory = ConversationBufferMemory(return_messages=True, memory_key='chat_history')

def run_agent(input_text: str):

    chat = ChatOpenAI()
    tools = [busca_wikipedia, actual_temperature_seach, find_cep, currency_search]
    tools_json = [convert_to_openai_function(tool) for tool in tools]
    tool_run = {tool.name: tool for tool in tools}

    template = [
        ('system', 'You are a friendly assistent called Ribamar' +
                    'Use the conversation hostory to remember details about the user.'),  # 游댮 For칞amos a AI considerar o hist칩rico no prompt
                    MessagesPlaceholder(variable_name="chat_history"),  # 游댮 Adicionamos o hist칩rico ao prompt
        ('user', '{input}'),
        MessagesPlaceholder(variable_name='agent_scratchpad')
    ]

    prompt = ChatPromptTemplate.from_messages(template)

    pass_through = RunnablePassthrough.assign(
        agent_scratchpad = lambda x: format_to_openai_function_messages(x['intermediate_steps']),
        chat_history=lambda x: memory.chat_memory.messages  # 游댮 Pegamos o hist칩rico da mem칩ria
    )
    agent_chain = pass_through | prompt | chat.bind(functions=tools_json) | OpenAIFunctionsAgentOutputParser()

    agent_executor = AgentExecutor(
        # '''
        #     agent=agent_chain: Esse par칙metro recebe um agente (agent_chain), que 칠 a cadeia de execu칞칚o do agente.
        #     O agente 칠 o componente respons치vel por decidir quais ferramentas usar e como estruturar a resposta com base na entrada do usu치rio.

        #     tools=tools: Aqui, passamos uma lista de ferramentas (tools) que o agente pode usar para realizar tarefas.
        #     As ferramentas podem ser APIs externas, consultas a bancos de dados, modelos de machine learning, entre outras funcionalidades.

        #     verbose=True: Ativa a sa칤da detalhada (modo verboso), 칰til para debugging, pois imprime logs sobre o funcionamento do agente.
        # '''
        agent=agent_chain,
        tools=tools,
        memory=memory, # 游댮 Mantemos a mesma inst칙ncia de mem칩ria
        verbose=True
    )

    return agent_executor.invoke({'input': input_text})

resposta = run_agent(input_text='Quantos reais s칚o 10000 d칩lares hoje?')
print(resposta)
